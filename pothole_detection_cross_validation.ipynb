{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FpGHI1hzZN7s"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from keras.models import Sequential, load_model\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from scipy import misc, ndimage\n",
    "from PIL import Image\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from keras.backend import sigmoid\n",
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "from keras.regularizers import l2, l1, l1_l2\n",
    "from keras.backend import manual_variable_initialization \n",
    "manual_variable_initialization(True)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import requests\n",
    "import json\n",
    "import glob\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, RemoteMonitor, LambdaCallback\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.image as mimg\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "import pandas as pd\n",
    "from scipy import misc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import random\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tg_sendtext(bot_message):\n",
    "\n",
    "    bot_token = ''\n",
    "    bot_chatID = '1220107026'\n",
    "    send_text = 'https://api.telegram.org/bot' + bot_token + '/sendMessage?chat_id=' + bot_chatID + '&parse_mode=Markdown&text=' + bot_message\n",
    "\n",
    "    response = requests.get(send_text)\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "def message_discord(message):\n",
    "    channelID = \"777064829063135234\" # enable dev mode on discord, right-click on the channel, copy ID\n",
    "    botToken = \"Nzc3MDYzODcyMjgzNTQxNTE0.X69_IA.TtsQh9eVhxFfeakGkQLqn9UDAxw\"    # get from the bot page. must be a bot, not a discord app\n",
    "\n",
    "    baseURL = \"https://discordapp.com/api/channels/{}/messages\".format(channelID)\n",
    "    headers = { \"Authorization\":\"Bot {}\".format(botToken),\n",
    "                \"User-Agent\":\"myBotThing (http://some.url, v0.1)\",\n",
    "                \"Content-Type\":\"application/json\", }\n",
    "\n",
    "    POSTedJSON =  json.dumps ( {\"content\":message} )\n",
    "\n",
    "    r = requests.post(baseURL, headers = headers, data = POSTedJSON)\n",
    "\n",
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(mdl, X_val, y_val):\n",
    "    true = 0\n",
    "    Y_pred = mdl.predict(X_val)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    for j in range(len(y_val)):\n",
    "        if y_pred[j] == y_val[j]:\n",
    "            true += 1\n",
    "    accc = (true/len(y_new))*100\n",
    "    return accc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hideInput": false,
    "hideOutput": false
   },
   "outputs": [],
   "source": [
    "def check_highest(folder_path1, train_max, max_acc, max_i):\n",
    "    temp_max_acc = [0]\n",
    "    temp_max_i = [0]\n",
    "    for i in os.listdir(folder_path1):\n",
    "        model = load_model(folder_path1 + i, custom_objects = {\"Activation\": Activation})\n",
    "        acc = check_accuracy(model, X_new, y_new)\n",
    "        print('Model Accuracy =', str(acc) + '%')\n",
    "        if acc > 92:\n",
    "            os.remove(folder_path1 + i)\n",
    "            new_name = i.replace(\".h5\",\"\") + '_' + str(round(acc, 2)) + '.h5'\n",
    "            model.save('good_models/' + new_name)\n",
    "            temp_max_acc.append(acc)\n",
    "            temp_max_i.append(new_name)\n",
    "        else:\n",
    "            os.remove(folder_path1 + i)\n",
    "    max_acc = np.append(max_acc, temp_max_acc)\n",
    "    max_i = np.append(max_i, temp_max_i)\n",
    "    maxx = np.amax(max_acc)\n",
    "    index = np.where(max_acc == maxx)\n",
    "    if maxx > train_max:\n",
    "        train_max = maxx\n",
    "        print('New High Accuracy =', train_max)\n",
    "        mess = str(train_max)\n",
    "        tg_sendtext('New High Accuracy = ' + mess)\n",
    "        message_discord('New High Accuracy = ' + mess)\n",
    "    print('The highest Accuracy:', max_i[index], 'with', str(maxx) + '%')\n",
    "    return train_max, acc, max_acc, max_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_highest_custom(folder_path1):\n",
    "    for i in os.listdir(folder_path1):\n",
    "        model = load_model(folder_path1 + i, custom_objects = {\"Activation\": Activation})\n",
    "        acc = check_accuracy(model, X_new, y_new)\n",
    "        if acc > 92:\n",
    "            os.remove(folder_path1 + i)\n",
    "            new_name = str(round((random.uniform(0, 10) + random.uniform(0, 10)) * random.uniform(0, 100), 5)) + i.replace(\".h5\",\"\") + '.h5'\n",
    "            model.save('checkpoints/' + new_name)\n",
    "        else:\n",
    "            os.remove(folder_path1 + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8rAxA1vcYu3",
    "outputId": "e450ff76-3198-4f34-8546-dd032e669d10"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive, output\n",
    "\n",
    "# drive.mount('/content/gdrive')\n",
    "root_path = 'pothole_detection'\n",
    "\n",
    "dataset = 'dataset'\n",
    "categories = ['pothole', 'no_pothole']\n",
    "test_categories = ['test_pothole', 'test_no_pothole']\n",
    "image_size = 120\n",
    "data = []\n",
    "data_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDc7zmzFZN70",
    "outputId": "2da23daa-4c0c-4b3e-a694-a75e8feaee2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_no_pothole 15205 1\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for category in categories:\n",
    "    folder = os.path.join(dataset, category)\n",
    "    label = categories.index(category)\n",
    "    for img in listdir_nohidden(folder):\n",
    "        try:\n",
    "            img_path = os.path.join(folder, img)\n",
    "            cnt+=1\n",
    "            print(category, cnt, label)\n",
    "            clear_output(wait = True)\n",
    "            img_array = cv2.imread(img_path)\n",
    "            img_array = cv2.resize(img_array, (image_size, image_size))\n",
    "            data.append([img_array, label])\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "\n",
    "for category in test_categories:\n",
    "    folder = os.path.join(dataset, category)\n",
    "    label = test_categories.index(category)\n",
    "    for img in listdir_nohidden(folder):\n",
    "        try:\n",
    "            img_path = os.path.join(folder, img)\n",
    "            cnt+=1\n",
    "            print(category, cnt, label)\n",
    "            clear_output(wait = True)\n",
    "            img_array = cv2.imread(img_path)\n",
    "            img_array = cv2.resize(img_array, (image_size, image_size))\n",
    "            data_test.append([img_array, label])\n",
    "        except Exception as e:\n",
    "            print(str(e))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xRt-Vfo_ZN72"
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "np.random.shuffle(data_test)\n",
    "\n",
    "X_old = []\n",
    "y_old = []\n",
    "X_old_test = []\n",
    "y_old_test = []\n",
    "\n",
    "for features, labels in data:\n",
    "    X_old.append(features)\n",
    "    y_old.append(labels)\n",
    "\n",
    "X_train = np.array(X_old)\n",
    "y_train = np.array(y_old)\n",
    "X_train = X_train/225\n",
    "\n",
    "for features, labels in data_test:\n",
    "    X_old_test.append(features)\n",
    "    y_old_test.append(labels)\n",
    "\n",
    "X_test = np.array(X_old_test)\n",
    "y_test = np.array(y_old_test)\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_pothole 614 1\n"
     ]
    }
   ],
   "source": [
    "root_path = ''\n",
    "dataset = 'dataset'\n",
    "categories = ['pothole', 'no_pothole']\n",
    "image_size = 120\n",
    "\n",
    "folder_path = 'validation'\n",
    "data_new = []\n",
    "\n",
    "cnt = 0\n",
    "for category in categories:\n",
    "    folder_new = os.path.join(dataset, folder_path, category)\n",
    "    label_new = categories.index(category)\n",
    "    for img_new in os.listdir(folder_new):\n",
    "        img_path_new = os.path.join(folder_new, img_new)\n",
    "        cnt+=1\n",
    "        print(category, cnt, label_new)\n",
    "        clear_output(wait = True)\n",
    "        img_array_new = cv2.imread(img_path_new)\n",
    "        img_array_new = cv2.resize(img_array_new, (image_size, image_size))\n",
    "        data_new.append([img_array_new, label_new])\n",
    "\n",
    "np.random.shuffle(data_new)\n",
    "X_old = []\n",
    "y_old = []\n",
    "\n",
    "for features_new, labels_new in data_new:\n",
    "    X_old.append(features_new)\n",
    "    y_old.append(labels_new)\n",
    "\n",
    "X_new = np.array(X_old)\n",
    "y_new = np.array(y_old)\n",
    "X_new = X_new/225"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx5oT_MsbgND"
   },
   "source": [
    "# **Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "5LF-vohXY5oU",
    "outputId": "153a76ef-c1ff-4076-bb2d-3176eee0ea1c"
   },
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "inputs = np.concatenate((X_train, X_test), axis=0)\n",
    "targets = np.concatenate((y_train, y_test), axis=0)\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hideOutput": false,
    "id": "7DX5Q9jobz6h"
   },
   "outputs": [],
   "source": [
    "def train_cross_val(input_layer_neurons_val, first_layer_neurons_val, second_layer_neurons_val, mes):\n",
    "    model = Sequential()\n",
    "    fold_no = 1\n",
    "    pat = 1\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n",
    "    model_checkpoint_best = ModelCheckpoint('saved_models/' + (datetime.datetime.utcnow()+datetime.timedelta(hours=5.5)).strftime(\"%d-%m-%Y--%H.%M.%S\") + '.h5', verbose=0, save_best_only=True, monitor='val_loss')\n",
    "    \n",
    "    model_checkpoint = ModelCheckpoint('temp_checkpoint/' + \"model_{epoch:02d}\" + (datetime.datetime.utcnow()+datetime.timedelta(hours=5.5)).strftime(\"%d-%m-%Y--%H.%M.%S\") + '.h5', verbose=0, save_best_only=False, monitor='val_loss')\n",
    "    \n",
    "    log_dir = \"logs/fit/\" + (datetime.datetime.utcnow()+datetime.timedelta(hours=5.5)).strftime(\"%d-%m-%Y--%H.%M.%S\")\n",
    "    logs = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    model.add(Conv2D(input_layer_neurons_val, (3, 3), kernel_initializer='random_normal', kernel_regularizer = l1(0.0005), activity_regularizer = l1(0.0005), activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(first_layer_neurons_val, input_shape = X_train.shape[1:], kernel_initializer='random_normal', activation = 'relu'))\n",
    "    model.add(Dropout(0.05))\n",
    "\n",
    "    model.add(Dense(second_layer_neurons_val, input_shape = X_train.shape[1:], kernel_initializer='random_normal', activation = 'relu'))\n",
    "    model.add(Dropout(0.05))\n",
    "\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "    ###\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    ###\n",
    "    \n",
    "    print('training')\n",
    "    print('Fold Num =', end=' ')\n",
    "    for train, test in kfold.split(inputs, targets):\n",
    "        print(fold_no)  \n",
    "        \n",
    "        model.fit(inputs[train], targets[train], epochs = 5, validation_split = 0.1, batch_size = 32, shuffle=True, verbose = 1, callbacks = [logs, early_stopping, model_checkpoint, model_checkpoint_best])\n",
    "\n",
    "        scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "        \n",
    "        tg_sendtext(f'Finished fold number {fold_no} of {mes} with accuracy = {scores[1]*100}%')\n",
    "        message_discord(f'Finished fold number {fold_no} of {mes} with accuracy = {scores[1]*100}%')\n",
    "        \n",
    "        acc_per_fold.append(scores[1] * 100)\n",
    "        loss_per_fold.append(scores[0])\n",
    "        fold_no = fold_no + 1\n",
    "        model.save('saved_models/' + (datetime.datetime.utcnow()+datetime.timedelta(hours=5.5)).strftime(\"%d-%m-%Y--%H.%M.%S\") + '.h5')\n",
    "        check_highest_custom('temp_checkpoint/')\n",
    "    print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Auto Trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Neurons = 24 16 14\n",
      "training\n",
      "Fold Num = 1\n",
      "Epoch 1/5\n",
      "  1/385 [..............................] - ETA: 0s - loss: 10.5777 - accuracy: 0.4375WARNING:tensorflow:From /Users/partthshah/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "385/385 [==============================] - 60s 155ms/step - loss: 0.7211 - accuracy: 0.7343 - val_loss: 0.5919 - val_accuracy: 0.7619\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 140ms/step - loss: 0.4257 - accuracy: 0.8296 - val_loss: 0.4986 - val_accuracy: 0.7772\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 56s 146ms/step - loss: 0.3274 - accuracy: 0.8753 - val_loss: 0.4595 - val_accuracy: 0.8247\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 53s 138ms/step - loss: 0.2341 - accuracy: 0.9206 - val_loss: 0.5525 - val_accuracy: 0.8247\n",
      "Epoch 00004: early stopping\n",
      "2\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 160ms/step - loss: 0.2310 - accuracy: 0.9294 - val_loss: 0.4549 - val_accuracy: 0.8473\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 144ms/step - loss: 0.1530 - accuracy: 0.9570 - val_loss: 0.5428 - val_accuracy: 0.8349\n",
      "Epoch 00002: early stopping\n",
      "3\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 60s 156ms/step - loss: 0.1389 - accuracy: 0.9664 - val_loss: 0.5197 - val_accuracy: 0.8459\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 140ms/step - loss: 0.1044 - accuracy: 0.9781 - val_loss: 0.8085 - val_accuracy: 0.8320\n",
      "Epoch 00002: early stopping\n",
      "4\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 162ms/step - loss: 0.1033 - accuracy: 0.9807 - val_loss: 0.7148 - val_accuracy: 0.8495\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 141ms/step - loss: 0.1010 - accuracy: 0.9804 - val_loss: 0.7636 - val_accuracy: 0.8400\n",
      "Epoch 00002: early stopping\n",
      "5\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 162ms/step - loss: 0.1015 - accuracy: 0.9810 - val_loss: 0.7152 - val_accuracy: 0.8466\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.0982 - accuracy: 0.9821 - val_loss: 0.7106 - val_accuracy: 0.8503\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 139ms/step - loss: 0.0773 - accuracy: 0.9878 - val_loss: 0.8749 - val_accuracy: 0.8393\n",
      "Epoch 00003: early stopping\n",
      "6\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 1:37 - loss: 0.0590 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1683s vs `on_train_batch_end` time: 0.3255s). Check your callbacks.\n",
      "385/385 [==============================] - 62s 160ms/step - loss: 0.1016 - accuracy: 0.9821 - val_loss: 0.7598 - val_accuracy: 0.8378\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 141ms/step - loss: 0.0650 - accuracy: 0.9927 - val_loss: 0.7746 - val_accuracy: 0.8408\n",
      "Epoch 00002: early stopping\n",
      "7\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 162ms/step - loss: 0.0983 - accuracy: 0.9838 - val_loss: 0.8862 - val_accuracy: 0.8386\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 142ms/step - loss: 0.0679 - accuracy: 0.9912 - val_loss: 0.8179 - val_accuracy: 0.8240\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 50s 131ms/step - loss: 0.0848 - accuracy: 0.9874 - val_loss: 0.8682 - val_accuracy: 0.7955\n",
      "Epoch 00003: early stopping\n",
      "8\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 63s 163ms/step - loss: 0.0764 - accuracy: 0.9874 - val_loss: 0.8231 - val_accuracy: 0.8415\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 144ms/step - loss: 0.0558 - accuracy: 0.9942 - val_loss: 0.8560 - val_accuracy: 0.8386\n",
      "Epoch 00002: early stopping\n",
      "9\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 160ms/step - loss: 0.0682 - accuracy: 0.9899 - val_loss: 0.8860 - val_accuracy: 0.8466\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 144ms/step - loss: 0.0562 - accuracy: 0.9942 - val_loss: 1.3066 - val_accuracy: 0.8123\n",
      "Epoch 00002: early stopping\n",
      "10\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 2:43 - loss: 0.0717 - accuracy: 0.9844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1580s vs `on_train_batch_end` time: 0.6310s). Check your callbacks.\n",
      "385/385 [==============================] - 63s 164ms/step - loss: 0.0710 - accuracy: 0.9888 - val_loss: 0.9804 - val_accuracy: 0.8335\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.0590 - accuracy: 0.9925 - val_loss: 0.8949 - val_accuracy: 0.8495\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 52s 135ms/step - loss: 0.0800 - accuracy: 0.9870 - val_loss: 0.8841 - val_accuracy: 0.8451\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 53s 138ms/step - loss: 0.0608 - accuracy: 0.9925 - val_loss: 0.7915 - val_accuracy: 0.8473\n",
      "Epoch 5/5\n",
      "385/385 [==============================] - 56s 145ms/step - loss: 0.0632 - accuracy: 0.9924 - val_loss: 0.8318 - val_accuracy: 0.8524\n",
      "Epoch 00005: early stopping\n",
      "Finished\n",
      "Model Accuracy = 87.29641693811075%\n",
      "Model Accuracy = 87.78501628664495%\n",
      "Model Accuracy = 86.15635179153095%\n",
      "Model Accuracy = 84.52768729641694%\n",
      "Model Accuracy = 87.78501628664495%\n",
      "Model Accuracy = 83.55048859934854%\n",
      "Model Accuracy = 87.45928338762215%\n",
      "Model Accuracy = 87.78501628664495%\n",
      "Model Accuracy = 86.64495114006515%\n",
      "Model Accuracy = 87.62214983713355%\n",
      "Model Accuracy = 86.64495114006515%\n",
      "Model Accuracy = 92.83387622149837%\n",
      "Model Accuracy = 87.45928338762215%\n",
      "New High Accuracy = 92.83387622149837\n",
      "The highest Accuracy: ['17-11-2020--12.54.00_92.83.h5'] with 92.83387622149837%\n",
      "------------------------------------------------------------------------\n",
      "4\n",
      "Neurons = 24 16 13\n",
      "training\n",
      "Fold Num = 1\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 60s 156ms/step - loss: 0.7781 - accuracy: 0.7062 - val_loss: 0.5975 - val_accuracy: 0.7896\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 141ms/step - loss: 0.4049 - accuracy: 0.8332 - val_loss: 0.4184 - val_accuracy: 0.8342\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 53s 139ms/step - loss: 0.2772 - accuracy: 0.8955 - val_loss: 0.3994 - val_accuracy: 0.8459\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.1719 - accuracy: 0.9492 - val_loss: 0.4690 - val_accuracy: 0.8539\n",
      "Epoch 00004: early stopping\n",
      "2\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 63s 163ms/step - loss: 0.1947 - accuracy: 0.9492 - val_loss: 0.5711 - val_accuracy: 0.8247\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.1190 - accuracy: 0.9715 - val_loss: 0.5034 - val_accuracy: 0.8671\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 139ms/step - loss: 0.0923 - accuracy: 0.9833 - val_loss: 0.7030 - val_accuracy: 0.8488\n",
      "Epoch 00003: early stopping\n",
      "3\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 60s 155ms/step - loss: 0.1196 - accuracy: 0.9729 - val_loss: 0.5342 - val_accuracy: 0.8561\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 56s 145ms/step - loss: 0.0766 - accuracy: 0.9879 - val_loss: 0.6203 - val_accuracy: 0.8539\n",
      "Epoch 00002: early stopping\n",
      "4\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 60s 155ms/step - loss: 0.0867 - accuracy: 0.9855 - val_loss: 0.6808 - val_accuracy: 0.8510\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 140ms/step - loss: 0.0729 - accuracy: 0.9894 - val_loss: 0.6573 - val_accuracy: 0.8393\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 56s 144ms/step - loss: 0.0706 - accuracy: 0.9882 - val_loss: 0.7377 - val_accuracy: 0.8532\n",
      "Epoch 00003: early stopping\n",
      "5\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 1:44 - loss: 0.0442 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1576s vs `on_train_batch_end` time: 0.3128s). Check your callbacks.\n",
      "385/385 [==============================] - 62s 162ms/step - loss: 0.0845 - accuracy: 0.9867 - val_loss: 0.7187 - val_accuracy: 0.8473\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 53s 139ms/step - loss: 0.0619 - accuracy: 0.9923 - val_loss: 0.8150 - val_accuracy: 0.8115\n",
      "Epoch 00002: early stopping\n",
      "6\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 63s 165ms/step - loss: 0.0619 - accuracy: 0.9933 - val_loss: 0.9480 - val_accuracy: 0.8356\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.0819 - accuracy: 0.9864 - val_loss: 0.7682 - val_accuracy: 0.8459\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 139ms/step - loss: 0.0702 - accuracy: 0.9911 - val_loss: 0.7849 - val_accuracy: 0.8554\n",
      "Epoch 00003: early stopping\n",
      "7\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 60s 156ms/step - loss: 0.0603 - accuracy: 0.9918 - val_loss: 0.8516 - val_accuracy: 0.8400\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.0709 - accuracy: 0.9897 - val_loss: 0.6472 - val_accuracy: 0.8335\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 55s 144ms/step - loss: 0.0651 - accuracy: 0.9911 - val_loss: 0.7721 - val_accuracy: 0.8524\n",
      "Epoch 00003: early stopping\n",
      "8\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 60s 157ms/step - loss: 0.0572 - accuracy: 0.9920 - val_loss: 0.8495 - val_accuracy: 0.8430\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 144ms/step - loss: 0.0667 - accuracy: 0.9903 - val_loss: 0.9074 - val_accuracy: 0.8605\n",
      "Epoch 00002: early stopping\n",
      "9\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 1:25 - loss: 0.0384 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1578s vs `on_train_batch_end` time: 0.2432s). Check your callbacks.\n",
      "385/385 [==============================] - 61s 159ms/step - loss: 0.0550 - accuracy: 0.9942 - val_loss: 0.7778 - val_accuracy: 0.8240\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 143ms/step - loss: 0.0508 - accuracy: 0.9937 - val_loss: 1.1507 - val_accuracy: 0.8247\n",
      "Epoch 00002: early stopping\n",
      "10\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 60s 156ms/step - loss: 0.0563 - accuracy: 0.9937 - val_loss: 0.9483 - val_accuracy: 0.8554\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.0470 - accuracy: 0.9957 - val_loss: 0.9287 - val_accuracy: 0.8634\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 140ms/step - loss: 0.0466 - accuracy: 0.9947 - val_loss: 0.9018 - val_accuracy: 0.8503\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 53s 139ms/step - loss: 0.0502 - accuracy: 0.9937 - val_loss: 0.8053 - val_accuracy: 0.8576\n",
      "Epoch 5/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.0717 - accuracy: 0.9884 - val_loss: 0.6832 - val_accuracy: 0.8554\n",
      "Finished\n",
      "Model Accuracy = 87.13355048859935%\n",
      "Model Accuracy = 87.13355048859935%\n",
      "Model Accuracy = 87.13355048859935%\n",
      "Model Accuracy = 86.97068403908796%\n",
      "Model Accuracy = 85.99348534201955%\n",
      "Model Accuracy = 82.89902280130293%\n",
      "Model Accuracy = 86.80781758957656%\n",
      "Model Accuracy = 85.99348534201955%\n",
      "Model Accuracy = 86.48208469055375%\n",
      "Model Accuracy = 86.64495114006515%\n",
      "Model Accuracy = 86.31921824104235%\n",
      "The highest Accuracy: ['17-11-2020--12.54.00_92.83.h5'] with 92.83387622149837%\n",
      "------------------------------------------------------------------------\n",
      "5\n",
      "Neurons = 24 16 12\n",
      "training\n",
      "Fold Num = 1\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 1:14 - loss: 11.3890 - accuracy: 0.5312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1442s vs `on_train_batch_end` time: 0.2285s). Check your callbacks.\n",
      "385/385 [==============================] - 60s 155ms/step - loss: 0.7331 - accuracy: 0.7389 - val_loss: 0.5962 - val_accuracy: 0.7312\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 56s 144ms/step - loss: 0.3934 - accuracy: 0.8407 - val_loss: 0.4458 - val_accuracy: 0.8042\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 139ms/step - loss: 0.2797 - accuracy: 0.8945 - val_loss: 0.4752 - val_accuracy: 0.8050\n",
      "Epoch 00003: early stopping\n",
      "2\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 63s 163ms/step - loss: 0.2581 - accuracy: 0.9139 - val_loss: 0.4115 - val_accuracy: 0.8320\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 140ms/step - loss: 0.1664 - accuracy: 0.9541 - val_loss: 0.4630 - val_accuracy: 0.8422\n",
      "Epoch 00002: early stopping\n",
      "3\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 63s 163ms/step - loss: 0.1419 - accuracy: 0.9633 - val_loss: 0.5206 - val_accuracy: 0.8378\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 56s 145ms/step - loss: 0.1051 - accuracy: 0.9785 - val_loss: 0.6319 - val_accuracy: 0.8495\n",
      "Epoch 00002: early stopping\n",
      "4\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 60s 155ms/step - loss: 0.1132 - accuracy: 0.9764 - val_loss: 0.6322 - val_accuracy: 0.8444\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 53s 139ms/step - loss: 0.0956 - accuracy: 0.9825 - val_loss: 0.8313 - val_accuracy: 0.8378\n",
      "Epoch 00002: early stopping\n",
      "5\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 60s 156ms/step - loss: 0.1089 - accuracy: 0.9811 - val_loss: 0.6949 - val_accuracy: 0.8356\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 143ms/step - loss: 0.0858 - accuracy: 0.9854 - val_loss: 0.7943 - val_accuracy: 0.8356\n",
      "Epoch 00002: early stopping\n",
      "6\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 161ms/step - loss: 0.0871 - accuracy: 0.9845 - val_loss: 0.9435 - val_accuracy: 0.8247\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 56s 145ms/step - loss: 0.0719 - accuracy: 0.9898 - val_loss: 0.8247 - val_accuracy: 0.8378\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 53s 138ms/step - loss: 0.0882 - accuracy: 0.9849 - val_loss: 0.8056 - val_accuracy: 0.8400\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 53s 137ms/step - loss: 0.0628 - accuracy: 0.9929 - val_loss: 0.8309 - val_accuracy: 0.8313\n",
      "Epoch 00004: early stopping\n",
      "7\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 59s 153ms/step - loss: 0.0915 - accuracy: 0.9849 - val_loss: 0.7606 - val_accuracy: 0.8400\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 56s 144ms/step - loss: 0.0634 - accuracy: 0.9921 - val_loss: 0.9760 - val_accuracy: 0.8378\n",
      "Epoch 00002: early stopping\n",
      "8\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 2:42 - loss: 0.0470 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1683s vs `on_train_batch_end` time: 0.6729s). Check your callbacks.\n",
      "385/385 [==============================] - 60s 157ms/step - loss: 0.0556 - accuracy: 0.9939 - val_loss: 0.9476 - val_accuracy: 0.8524\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 53s 139ms/step - loss: 0.0607 - accuracy: 0.9925 - val_loss: 0.9294 - val_accuracy: 0.8503\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 139ms/step - loss: 0.0688 - accuracy: 0.9896 - val_loss: 0.9751 - val_accuracy: 0.8408\n",
      "Epoch 00003: early stopping\n",
      "9\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 60s 155ms/step - loss: 0.0638 - accuracy: 0.9907 - val_loss: 1.0532 - val_accuracy: 0.8356\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 140ms/step - loss: 0.0545 - accuracy: 0.9942 - val_loss: 0.9322 - val_accuracy: 0.8342\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 139ms/step - loss: 0.0619 - accuracy: 0.9916 - val_loss: 0.8714 - val_accuracy: 0.8517\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 54s 140ms/step - loss: 0.0656 - accuracy: 0.9904 - val_loss: 0.7959 - val_accuracy: 0.8342\n",
      "Epoch 5/5\n",
      "385/385 [==============================] - 54s 140ms/step - loss: 0.0576 - accuracy: 0.9929 - val_loss: 0.8058 - val_accuracy: 0.8152\n",
      "Epoch 00005: early stopping\n",
      "10\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 161ms/step - loss: 0.0613 - accuracy: 0.9919 - val_loss: 1.0288 - val_accuracy: 0.8349\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 144ms/step - loss: 0.0519 - accuracy: 0.9945 - val_loss: 1.0719 - val_accuracy: 0.8305\n",
      "Epoch 00002: early stopping\n",
      "Finished\n",
      "Model Accuracy = 87.29641693811075%\n",
      "Model Accuracy = 85.34201954397395%\n",
      "Model Accuracy = 86.48208469055375%\n",
      "Model Accuracy = 86.64495114006515%\n",
      "Model Accuracy = 84.85342019543974%\n",
      "Model Accuracy = 85.99348534201955%\n",
      "Model Accuracy = 86.48208469055375%\n",
      "Model Accuracy = 85.34201954397395%\n",
      "Model Accuracy = 81.59609120521174%\n",
      "Model Accuracy = 85.66775244299674%\n",
      "Model Accuracy = 85.99348534201955%\n",
      "The highest Accuracy: ['17-11-2020--12.54.00_92.83.h5'] with 92.83387622149837%\n",
      "------------------------------------------------------------------------\n",
      "6\n",
      "Neurons = 24 15 16\n",
      "training\n",
      "Fold Num = 1\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 1:31 - loss: 13.7835 - accuracy: 0.5156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1750s vs `on_train_batch_end` time: 0.2698s). Check your callbacks.\n",
      "385/385 [==============================] - 64s 165ms/step - loss: 0.8650 - accuracy: 0.7400 - val_loss: 0.5746 - val_accuracy: 0.7801\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.4162 - accuracy: 0.8312 - val_loss: 0.4187 - val_accuracy: 0.8305\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 53s 137ms/step - loss: 0.3149 - accuracy: 0.8787 - val_loss: 0.4037 - val_accuracy: 0.8371\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 52s 136ms/step - loss: 0.2294 - accuracy: 0.9241 - val_loss: 0.4388 - val_accuracy: 0.8546\n",
      "Epoch 00004: early stopping\n",
      "2\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 1:55 - loss: 0.1367 - accuracy: 0.9531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1911s vs `on_train_batch_end` time: 0.3738s). Check your callbacks.\n",
      "385/385 [==============================] - 60s 155ms/step - loss: 0.2132 - accuracy: 0.9390 - val_loss: 0.4493 - val_accuracy: 0.8459\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 58s 150ms/step - loss: 0.1337 - accuracy: 0.9683 - val_loss: 0.5321 - val_accuracy: 0.8364\n",
      "Epoch 00002: early stopping\n",
      "3\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 161ms/step - loss: 0.1207 - accuracy: 0.9705 - val_loss: 0.5376 - val_accuracy: 0.8576\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 140ms/step - loss: 0.1209 - accuracy: 0.9725 - val_loss: 0.6559 - val_accuracy: 0.8349\n",
      "Epoch 00002: early stopping\n",
      "4\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 1:37 - loss: 0.1455 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1758s vs `on_train_batch_end` time: 0.2822s). Check your callbacks.\n",
      "385/385 [==============================] - 60s 156ms/step - loss: 0.1150 - accuracy: 0.9726 - val_loss: 0.5744 - val_accuracy: 0.8590\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 143ms/step - loss: 0.0818 - accuracy: 0.9855 - val_loss: 0.6629 - val_accuracy: 0.8532\n",
      "Epoch 00002: early stopping\n",
      "5\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 162ms/step - loss: 0.0891 - accuracy: 0.9833 - val_loss: 0.6026 - val_accuracy: 0.8422\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 143ms/step - loss: 0.0837 - accuracy: 0.9865 - val_loss: 0.6949 - val_accuracy: 0.8400\n",
      "Epoch 00002: early stopping\n",
      "6\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 60s 156ms/step - loss: 0.0799 - accuracy: 0.9876 - val_loss: 0.6696 - val_accuracy: 0.8422\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 143ms/step - loss: 0.0704 - accuracy: 0.9911 - val_loss: 0.5902 - val_accuracy: 0.8386\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 53s 138ms/step - loss: 0.0795 - accuracy: 0.9857 - val_loss: 0.6373 - val_accuracy: 0.8532\n",
      "Epoch 00003: early stopping\n",
      "7\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 1:17 - loss: 0.0708 - accuracy: 0.9844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1449s vs `on_train_batch_end` time: 0.2535s). Check your callbacks.\n",
      "385/385 [==============================] - 63s 163ms/step - loss: 0.0698 - accuracy: 0.9894 - val_loss: 0.8700 - val_accuracy: 0.8371\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 141ms/step - loss: 0.0686 - accuracy: 0.9908 - val_loss: 0.7973 - val_accuracy: 0.8466\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 53s 138ms/step - loss: 0.0611 - accuracy: 0.9917 - val_loss: 0.7587 - val_accuracy: 0.8583\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 53s 138ms/step - loss: 0.0711 - accuracy: 0.9898 - val_loss: 0.7942 - val_accuracy: 0.8430\n",
      "Epoch 00004: early stopping\n",
      "8\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 60s 157ms/step - loss: 0.0750 - accuracy: 0.9880 - val_loss: 0.8382 - val_accuracy: 0.8451\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 144ms/step - loss: 0.0610 - accuracy: 0.9917 - val_loss: 0.8478 - val_accuracy: 0.8554\n",
      "Epoch 00002: early stopping\n",
      "9\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 61s 160ms/step - loss: 0.0634 - accuracy: 0.9915 - val_loss: 0.9150 - val_accuracy: 0.8510\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 141ms/step - loss: 0.0710 - accuracy: 0.9881 - val_loss: 0.9509 - val_accuracy: 0.8349\n",
      "Epoch 00002: early stopping\n",
      "10\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 160ms/step - loss: 0.0592 - accuracy: 0.9925 - val_loss: 0.8389 - val_accuracy: 0.8430\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 143ms/step - loss: 0.0587 - accuracy: 0.9927 - val_loss: 0.8959 - val_accuracy: 0.8378\n",
      "Epoch 00002: early stopping\n",
      "Finished\n",
      "Model Accuracy = 87.13355048859935%\n",
      "Model Accuracy = 86.48208469055375%\n",
      "Model Accuracy = 83.71335504885994%\n",
      "Model Accuracy = 87.94788273615634%\n",
      "Model Accuracy = 86.48208469055375%\n",
      "Model Accuracy = 86.48208469055375%\n",
      "Model Accuracy = 86.97068403908796%\n",
      "Model Accuracy = 87.29641693811075%\n",
      "Model Accuracy = 85.99348534201955%\n",
      "Model Accuracy = 88.11074918566774%\n",
      "Model Accuracy = 85.34201954397395%\n",
      "The highest Accuracy: ['17-11-2020--12.54.00_92.83.h5'] with 92.83387622149837%\n",
      "------------------------------------------------------------------------\n",
      "7\n",
      "Neurons = 24 15 15\n",
      "training\n",
      "Fold Num = 1\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 161ms/step - loss: 0.7439 - accuracy: 0.6885 - val_loss: 0.5739 - val_accuracy: 0.7728\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 143ms/step - loss: 0.4207 - accuracy: 0.8255 - val_loss: 0.4690 - val_accuracy: 0.7845\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 141ms/step - loss: 0.2998 - accuracy: 0.8891 - val_loss: 0.4247 - val_accuracy: 0.8415\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 54s 141ms/step - loss: 0.1923 - accuracy: 0.9427 - val_loss: 0.4955 - val_accuracy: 0.8444\n",
      "Epoch 00004: early stopping\n",
      "2\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 5:05 - loss: 0.1267 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1779s vs `on_train_batch_end` time: 1.3774s). Check your callbacks.\n",
      "385/385 [==============================] - 64s 165ms/step - loss: 0.2121 - accuracy: 0.9427 - val_loss: 0.4369 - val_accuracy: 0.8568\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 144ms/step - loss: 0.1183 - accuracy: 0.9734 - val_loss: 0.6937 - val_accuracy: 0.8451\n",
      "Epoch 00002: early stopping\n",
      "3\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 160ms/step - loss: 0.1288 - accuracy: 0.9700 - val_loss: 0.4827 - val_accuracy: 0.8663\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 143ms/step - loss: 0.0825 - accuracy: 0.9870 - val_loss: 0.5626 - val_accuracy: 0.8598\n",
      "Epoch 00002: early stopping\n",
      "4\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 61s 157ms/step - loss: 0.1017 - accuracy: 0.9799 - val_loss: 0.7106 - val_accuracy: 0.8364\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 143ms/step - loss: 0.0773 - accuracy: 0.9877 - val_loss: 0.6771 - val_accuracy: 0.8554\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 141ms/step - loss: 0.0833 - accuracy: 0.9858 - val_loss: 0.6963 - val_accuracy: 0.8444\n",
      "Epoch 00003: early stopping\n",
      "5\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 1:56 - loss: 0.0535 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1924s vs `on_train_batch_end` time: 0.4080s). Check your callbacks.\n",
      "385/385 [==============================] - 62s 162ms/step - loss: 0.0838 - accuracy: 0.9853 - val_loss: 0.7028 - val_accuracy: 0.8568\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 139ms/step - loss: 0.0731 - accuracy: 0.9890 - val_loss: 0.5688 - val_accuracy: 0.8685\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 53s 137ms/step - loss: 0.0742 - accuracy: 0.9882 - val_loss: 0.6112 - val_accuracy: 0.8466\n",
      "Epoch 00003: early stopping\n",
      "6\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 63s 163ms/step - loss: 0.0771 - accuracy: 0.9882 - val_loss: 0.5731 - val_accuracy: 0.8590\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 141ms/step - loss: 0.0663 - accuracy: 0.9912 - val_loss: 0.7453 - val_accuracy: 0.8590\n",
      "Epoch 00002: early stopping\n",
      "7\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 161ms/step - loss: 0.0832 - accuracy: 0.9857 - val_loss: 0.9289 - val_accuracy: 0.8115\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.0712 - accuracy: 0.9901 - val_loss: 0.6844 - val_accuracy: 0.8517\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 139ms/step - loss: 0.0631 - accuracy: 0.9920 - val_loss: 0.7411 - val_accuracy: 0.8503\n",
      "Epoch 00003: early stopping\n",
      "8\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 63s 164ms/step - loss: 0.0597 - accuracy: 0.9920 - val_loss: 0.8813 - val_accuracy: 0.8488\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 140ms/step - loss: 0.0648 - accuracy: 0.9899 - val_loss: 0.7789 - val_accuracy: 0.8568\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 139ms/step - loss: 0.0640 - accuracy: 0.9903 - val_loss: 0.7013 - val_accuracy: 0.8663\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 54s 141ms/step - loss: 0.0635 - accuracy: 0.9907 - val_loss: 1.0794 - val_accuracy: 0.8305\n",
      "Epoch 00004: early stopping\n",
      "9\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 63s 163ms/step - loss: 0.0543 - accuracy: 0.9935 - val_loss: 0.6549 - val_accuracy: 0.8561\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.0615 - accuracy: 0.9910 - val_loss: 0.7333 - val_accuracy: 0.8503\n",
      "Epoch 00002: early stopping\n",
      "10\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 64s 165ms/step - loss: 0.0759 - accuracy: 0.9877 - val_loss: 0.6308 - val_accuracy: 0.8408\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.0626 - accuracy: 0.9924 - val_loss: 0.7531 - val_accuracy: 0.8532\n",
      "Epoch 00002: early stopping\n",
      "Finished\n",
      "Model Accuracy = 87.13355048859935%\n",
      "Model Accuracy = 87.29641693811075%\n",
      "Model Accuracy = 89.25081433224756%\n",
      "Model Accuracy = 87.29641693811075%\n",
      "Model Accuracy = 87.94788273615634%\n",
      "Model Accuracy = 87.62214983713355%\n",
      "Model Accuracy = 87.45928338762215%\n",
      "Model Accuracy = 87.13355048859935%\n",
      "Model Accuracy = 87.94788273615634%\n",
      "Model Accuracy = 88.27361563517914%\n",
      "Model Accuracy = 87.78501628664495%\n",
      "The highest Accuracy: ['17-11-2020--12.54.00_92.83.h5'] with 92.83387622149837%\n",
      "------------------------------------------------------------------------\n",
      "8\n",
      "Neurons = 24 15 14\n",
      "training\n",
      "Fold Num = 1\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 61s 157ms/step - loss: 0.7451 - accuracy: 0.7315 - val_loss: 0.5964 - val_accuracy: 0.7728\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 56s 146ms/step - loss: 0.3902 - accuracy: 0.8429 - val_loss: 0.4809 - val_accuracy: 0.7882\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 140ms/step - loss: 0.2682 - accuracy: 0.9032 - val_loss: 0.4451 - val_accuracy: 0.8108\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 54s 140ms/step - loss: 0.1892 - accuracy: 0.9410 - val_loss: 0.4839 - val_accuracy: 0.8378\n",
      "Epoch 00004: early stopping\n",
      "2\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 1:38 - loss: 0.1553 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1765s vs `on_train_batch_end` time: 0.2994s). Check your callbacks.\n",
      "385/385 [==============================] - 61s 157ms/step - loss: 0.2010 - accuracy: 0.9473 - val_loss: 0.4066 - val_accuracy: 0.8546\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 143ms/step - loss: 0.1268 - accuracy: 0.9695 - val_loss: 0.4902 - val_accuracy: 0.8568\n",
      "Epoch 00002: early stopping\n",
      "3\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 162ms/step - loss: 0.1144 - accuracy: 0.9754 - val_loss: 0.5410 - val_accuracy: 0.8561\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 141ms/step - loss: 0.0911 - accuracy: 0.9832 - val_loss: 0.7014 - val_accuracy: 0.8495\n",
      "Epoch 00002: early stopping\n",
      "4\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 1:55 - loss: 0.1200 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1783s vs `on_train_batch_end` time: 0.3739s). Check your callbacks.\n",
      "385/385 [==============================] - 62s 161ms/step - loss: 0.0851 - accuracy: 0.9852 - val_loss: 0.6744 - val_accuracy: 0.8488\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 53s 139ms/step - loss: 0.0760 - accuracy: 0.9889 - val_loss: 0.7158 - val_accuracy: 0.8495\n",
      "Epoch 00002: early stopping\n",
      "5\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 162ms/step - loss: 0.0945 - accuracy: 0.9828 - val_loss: 0.7100 - val_accuracy: 0.8561\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.0767 - accuracy: 0.9880 - val_loss: 0.5681 - val_accuracy: 0.8700\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 53s 138ms/step - loss: 0.0741 - accuracy: 0.9884 - val_loss: 0.6568 - val_accuracy: 0.8481\n",
      "Epoch 00003: early stopping\n",
      "6\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 60s 156ms/step - loss: 0.0758 - accuracy: 0.9877 - val_loss: 0.8360 - val_accuracy: 0.8349\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 141ms/step - loss: 0.0683 - accuracy: 0.9902 - val_loss: 0.7360 - val_accuracy: 0.8488\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 140ms/step - loss: 0.0762 - accuracy: 0.9881 - val_loss: 0.8338 - val_accuracy: 0.8422\n",
      "Epoch 00003: early stopping\n",
      "7\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 64s 165ms/step - loss: 0.0670 - accuracy: 0.9908 - val_loss: 0.8458 - val_accuracy: 0.8320\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 144ms/step - loss: 0.0543 - accuracy: 0.9943 - val_loss: 0.7511 - val_accuracy: 0.8517\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 140ms/step - loss: 0.0752 - accuracy: 0.9863 - val_loss: 0.6783 - val_accuracy: 0.8488\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 52s 136ms/step - loss: 0.0567 - accuracy: 0.9929 - val_loss: 0.7534 - val_accuracy: 0.8327\n",
      "Epoch 00004: early stopping\n",
      "8\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 63s 163ms/step - loss: 0.0558 - accuracy: 0.9929 - val_loss: 0.8930 - val_accuracy: 0.8430\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.0591 - accuracy: 0.9920 - val_loss: 0.7527 - val_accuracy: 0.8378\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 53s 138ms/step - loss: 0.0549 - accuracy: 0.9929 - val_loss: 0.9949 - val_accuracy: 0.8269\n",
      "Epoch 00003: early stopping\n",
      "9\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 61s 158ms/step - loss: 0.0605 - accuracy: 0.9912 - val_loss: 0.8660 - val_accuracy: 0.8283\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 53s 138ms/step - loss: 0.0540 - accuracy: 0.9933 - val_loss: 0.8768 - val_accuracy: 0.8349\n",
      "Epoch 00002: early stopping\n",
      "10\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 61s 157ms/step - loss: 0.0541 - accuracy: 0.9939 - val_loss: 1.0302 - val_accuracy: 0.8371\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 140ms/step - loss: 0.0513 - accuracy: 0.9941 - val_loss: 0.8864 - val_accuracy: 0.8488\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 56s 144ms/step - loss: 0.0659 - accuracy: 0.9907 - val_loss: 0.8291 - val_accuracy: 0.8430\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 53s 138ms/step - loss: 0.0489 - accuracy: 0.9950 - val_loss: 1.0409 - val_accuracy: 0.8422\n",
      "Epoch 00004: early stopping\n",
      "Finished\n",
      "Model Accuracy = 85.34201954397395%\n",
      "Model Accuracy = 86.64495114006515%\n",
      "Model Accuracy = 86.64495114006515%\n",
      "Model Accuracy = 87.29641693811075%\n",
      "Model Accuracy = 89.25081433224756%\n",
      "Model Accuracy = 87.29641693811075%\n",
      "Model Accuracy = 89.08794788273615%\n",
      "Model Accuracy = 87.78501628664495%\n",
      "Model Accuracy = 86.15635179153095%\n",
      "Model Accuracy = 87.78501628664495%\n",
      "Model Accuracy = 86.15635179153095%\n",
      "The highest Accuracy: ['17-11-2020--12.54.00_92.83.h5'] with 92.83387622149837%\n",
      "------------------------------------------------------------------------\n",
      "9\n",
      "Neurons = 24 15 13\n",
      "training\n",
      "Fold Num = 1\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 1:21 - loss: 10.0642 - accuracy: 0.3906WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1489s vs `on_train_batch_end` time: 0.2748s). Check your callbacks.\n",
      "385/385 [==============================] - 62s 161ms/step - loss: 0.6900 - accuracy: 0.7280 - val_loss: 0.6793 - val_accuracy: 0.5376\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 57s 147ms/step - loss: 0.4152 - accuracy: 0.8280 - val_loss: 0.4977 - val_accuracy: 0.7845\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.2985 - accuracy: 0.8848 - val_loss: 0.4573 - val_accuracy: 0.8269\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 53s 137ms/step - loss: 0.1911 - accuracy: 0.9415 - val_loss: 0.5422 - val_accuracy: 0.8291\n",
      "Epoch 00004: early stopping\n",
      "2\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 63s 163ms/step - loss: 0.2061 - accuracy: 0.9431 - val_loss: 0.5457 - val_accuracy: 0.8218\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 141ms/step - loss: 0.1289 - accuracy: 0.9675 - val_loss: 0.5869 - val_accuracy: 0.8634\n",
      "Epoch 00002: early stopping\n",
      "3\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 61s 158ms/step - loss: 0.1069 - accuracy: 0.9779 - val_loss: 0.7824 - val_accuracy: 0.8123\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 56s 145ms/step - loss: 0.0988 - accuracy: 0.9782 - val_loss: 0.7402 - val_accuracy: 0.8605\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 53s 139ms/step - loss: 0.0812 - accuracy: 0.9851 - val_loss: 0.7738 - val_accuracy: 0.8568\n",
      "Epoch 00003: early stopping\n",
      "4\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 61s 159ms/step - loss: 0.0948 - accuracy: 0.9827 - val_loss: 0.6896 - val_accuracy: 0.8495\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 54s 142ms/step - loss: 0.0898 - accuracy: 0.9838 - val_loss: 0.6503 - val_accuracy: 0.8378\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 139ms/step - loss: 0.0984 - accuracy: 0.9828 - val_loss: 0.7274 - val_accuracy: 0.8473\n",
      "Epoch 00003: early stopping\n",
      "5\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 61s 158ms/step - loss: 0.0761 - accuracy: 0.9878 - val_loss: 0.6459 - val_accuracy: 0.8305\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.0746 - accuracy: 0.9885 - val_loss: 0.9482 - val_accuracy: 0.8349\n",
      "Epoch 00002: early stopping\n",
      "6\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 63s 163ms/step - loss: 0.0728 - accuracy: 0.9877 - val_loss: 0.8538 - val_accuracy: 0.8466\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 143ms/step - loss: 0.0754 - accuracy: 0.9877 - val_loss: 0.8479 - val_accuracy: 0.8451\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 52s 135ms/step - loss: 0.0634 - accuracy: 0.9910 - val_loss: 0.9104 - val_accuracy: 0.8408\n",
      "Epoch 00003: early stopping\n",
      "7\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 2:48 - loss: 0.0679 - accuracy: 0.9844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1898s vs `on_train_batch_end` time: 0.6173s). Check your callbacks.\n",
      "385/385 [==============================] - 61s 158ms/step - loss: 0.0809 - accuracy: 0.9867 - val_loss: 0.7826 - val_accuracy: 0.8466\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 53s 137ms/step - loss: 0.0553 - accuracy: 0.9933 - val_loss: 0.8985 - val_accuracy: 0.8473\n",
      "Epoch 00002: early stopping\n",
      "8\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 162ms/step - loss: 0.0613 - accuracy: 0.9910 - val_loss: 0.7991 - val_accuracy: 0.8451\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.0488 - accuracy: 0.9941 - val_loss: 1.0240 - val_accuracy: 0.8356\n",
      "Epoch 00002: early stopping\n",
      "9\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 63s 164ms/step - loss: 0.0582 - accuracy: 0.9928 - val_loss: 1.2860 - val_accuracy: 0.8152\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 143ms/step - loss: 0.0696 - accuracy: 0.9909 - val_loss: 0.8876 - val_accuracy: 0.8422\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 55s 142ms/step - loss: 0.0677 - accuracy: 0.9909 - val_loss: 0.9576 - val_accuracy: 0.8364\n",
      "Epoch 00003: early stopping\n",
      "10\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 61s 159ms/step - loss: 0.0620 - accuracy: 0.9903 - val_loss: 0.7983 - val_accuracy: 0.8554\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 56s 145ms/step - loss: 0.0608 - accuracy: 0.9916 - val_loss: 0.7966 - val_accuracy: 0.8364\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 54s 141ms/step - loss: 0.0512 - accuracy: 0.9938 - val_loss: 0.8904 - val_accuracy: 0.8568\n",
      "Epoch 00003: early stopping\n",
      "Finished\n",
      "Model Accuracy = 86.48208469055375%\n",
      "Model Accuracy = 87.45928338762215%\n",
      "Model Accuracy = 86.64495114006515%\n",
      "Model Accuracy = 86.64495114006515%\n",
      "Model Accuracy = 86.15635179153095%\n",
      "Model Accuracy = 85.66775244299674%\n",
      "Model Accuracy = 85.17915309446255%\n",
      "Model Accuracy = 87.78501628664495%\n",
      "Model Accuracy = 85.17915309446255%\n",
      "Model Accuracy = 86.31921824104235%\n",
      "Model Accuracy = 84.52768729641694%\n",
      "The highest Accuracy: ['17-11-2020--12.54.00_92.83.h5'] with 92.83387622149837%\n",
      "------------------------------------------------------------------------\n",
      "10\n",
      "Neurons = 24 15 12\n",
      "training\n",
      "Fold Num = 1\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 64s 165ms/step - loss: 0.6134 - accuracy: 0.7465 - val_loss: 0.5960 - val_accuracy: 0.7560\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 144ms/step - loss: 0.3985 - accuracy: 0.8344 - val_loss: 0.4415 - val_accuracy: 0.8188\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 53s 139ms/step - loss: 0.2820 - accuracy: 0.8941 - val_loss: 0.4762 - val_accuracy: 0.8174\n",
      "Epoch 00003: early stopping\n",
      "2\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 161ms/step - loss: 0.2662 - accuracy: 0.9152 - val_loss: 0.4980 - val_accuracy: 0.8283\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 144ms/step - loss: 0.1521 - accuracy: 0.9566 - val_loss: 0.6199 - val_accuracy: 0.8356\n",
      "Epoch 00002: early stopping\n",
      "3\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 61s 157ms/step - loss: 0.1334 - accuracy: 0.9660 - val_loss: 0.5994 - val_accuracy: 0.8320\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 143ms/step - loss: 0.0982 - accuracy: 0.9791 - val_loss: 0.5974 - val_accuracy: 0.8393\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 59s 153ms/step - loss: 0.0937 - accuracy: 0.9805 - val_loss: 0.7402 - val_accuracy: 0.8393\n",
      "Epoch 00003: early stopping\n",
      "4\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 64s 167ms/step - loss: 0.0961 - accuracy: 0.9821 - val_loss: 0.7907 - val_accuracy: 0.8386\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 57s 149ms/step - loss: 0.0879 - accuracy: 0.9836 - val_loss: 0.6415 - val_accuracy: 0.8524\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 56s 147ms/step - loss: 0.0825 - accuracy: 0.9868 - val_loss: 0.8719 - val_accuracy: 0.8327\n",
      "Epoch 00003: early stopping\n",
      "5\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 65s 168ms/step - loss: 0.0816 - accuracy: 0.9835 - val_loss: 0.8420 - val_accuracy: 0.8517\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 60s 155ms/step - loss: 0.0654 - accuracy: 0.9897 - val_loss: 0.8733 - val_accuracy: 0.8466\n",
      "Epoch 00002: early stopping\n",
      "6\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 2:09 - loss: 0.1452 - accuracy: 0.9844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2357s vs `on_train_batch_end` time: 0.4320s). Check your callbacks.\n",
      "385/385 [==============================] - 64s 166ms/step - loss: 0.0692 - accuracy: 0.9897 - val_loss: 1.3366 - val_accuracy: 0.8042\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 58s 149ms/step - loss: 0.0694 - accuracy: 0.9894 - val_loss: 0.9191 - val_accuracy: 0.8481\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 57s 147ms/step - loss: 0.0708 - accuracy: 0.9895 - val_loss: 0.7681 - val_accuracy: 0.8517\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 57s 148ms/step - loss: 0.0685 - accuracy: 0.9897 - val_loss: 0.7928 - val_accuracy: 0.8356\n",
      "Epoch 00004: early stopping\n",
      "7\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 64s 166ms/step - loss: 0.0694 - accuracy: 0.9889 - val_loss: 0.8171 - val_accuracy: 0.8503\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 57s 148ms/step - loss: 0.0638 - accuracy: 0.9907 - val_loss: 1.1366 - val_accuracy: 0.7999\n",
      "Epoch 00002: early stopping\n",
      "8\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 64s 166ms/step - loss: 0.0900 - accuracy: 0.9819 - val_loss: 0.7492 - val_accuracy: 0.8503\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 57s 148ms/step - loss: 0.0563 - accuracy: 0.9932 - val_loss: 0.8897 - val_accuracy: 0.8444\n",
      "Epoch 00002: early stopping\n",
      "9\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 65s 169ms/step - loss: 0.0517 - accuracy: 0.9940 - val_loss: 0.9052 - val_accuracy: 0.8466\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 57s 149ms/step - loss: 0.0685 - accuracy: 0.9894 - val_loss: 0.9039 - val_accuracy: 0.8327\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 55s 144ms/step - loss: 0.0525 - accuracy: 0.9933 - val_loss: 0.9897 - val_accuracy: 0.8386\n",
      "Epoch 00003: early stopping\n",
      "10\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 64s 166ms/step - loss: 0.0575 - accuracy: 0.9918 - val_loss: 0.9008 - val_accuracy: 0.8408\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 59s 153ms/step - loss: 0.0613 - accuracy: 0.9916 - val_loss: 0.9400 - val_accuracy: 0.8437\n",
      "Epoch 00002: early stopping\n",
      "Finished\n",
      "Model Accuracy = 85.01628664495115%\n",
      "Model Accuracy = 85.17915309446255%\n",
      "Model Accuracy = 85.99348534201955%\n",
      "Model Accuracy = 84.03908794788273%\n",
      "Model Accuracy = 84.85342019543974%\n",
      "Model Accuracy = 82.24755700325733%\n",
      "Model Accuracy = 85.17915309446255%\n",
      "Model Accuracy = 85.83061889250814%\n",
      "Model Accuracy = 86.15635179153095%\n",
      "Model Accuracy = 85.50488599348535%\n",
      "Model Accuracy = 84.85342019543974%\n",
      "The highest Accuracy: ['17-11-2020--12.54.00_92.83.h5'] with 92.83387622149837%\n",
      "------------------------------------------------------------------------\n",
      "11\n",
      "Neurons = 24 14 16\n",
      "training\n",
      "Fold Num = 1\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 62s 161ms/step - loss: 0.6526 - accuracy: 0.7562 - val_loss: 0.6356 - val_accuracy: 0.6662\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 55s 144ms/step - loss: 0.4009 - accuracy: 0.8422 - val_loss: 0.4734 - val_accuracy: 0.7984\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 56s 147ms/step - loss: 0.2801 - accuracy: 0.9002 - val_loss: 0.4267 - val_accuracy: 0.8210\n",
      "Epoch 4/5\n",
      "385/385 [==============================] - 57s 147ms/step - loss: 0.1821 - accuracy: 0.9462 - val_loss: 0.5326 - val_accuracy: 0.8130\n",
      "Epoch 00004: early stopping\n",
      "2\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 66s 171ms/step - loss: 0.2181 - accuracy: 0.9400 - val_loss: 0.4397 - val_accuracy: 0.8415\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 57s 148ms/step - loss: 0.1319 - accuracy: 0.9694 - val_loss: 0.5308 - val_accuracy: 0.8378\n",
      "Epoch 00002: early stopping\n",
      "3\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 3:03 - loss: 0.1073 - accuracy: 0.9844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2702s vs `on_train_batch_end` time: 0.6473s). Check your callbacks.\n",
      "385/385 [==============================] - 65s 170ms/step - loss: 0.1189 - accuracy: 0.9725 - val_loss: 0.6721 - val_accuracy: 0.8218\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 57s 148ms/step - loss: 0.0994 - accuracy: 0.9812 - val_loss: 0.6814 - val_accuracy: 0.8430\n",
      "Epoch 00002: early stopping\n",
      "4\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 1:50 - loss: 0.0991 - accuracy: 0.9844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2264s vs `on_train_batch_end` time: 0.3404s). Check your callbacks.\n",
      "385/385 [==============================] - 64s 165ms/step - loss: 0.0890 - accuracy: 0.9830 - val_loss: 0.7553 - val_accuracy: 0.8327\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 57s 148ms/step - loss: 0.1081 - accuracy: 0.9772 - val_loss: 0.8134 - val_accuracy: 0.8400\n",
      "Epoch 00002: early stopping\n",
      "5\n",
      "Epoch 1/5\n",
      "  2/385 [..............................] - ETA: 1:55 - loss: 0.0510 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2080s vs `on_train_batch_end` time: 0.3826s). Check your callbacks.\n",
      "385/385 [==============================] - 65s 169ms/step - loss: 0.0843 - accuracy: 0.9853 - val_loss: 0.8194 - val_accuracy: 0.8130\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 57s 148ms/step - loss: 0.0745 - accuracy: 0.9877 - val_loss: 0.8299 - val_accuracy: 0.8444\n",
      "Epoch 00002: early stopping\n",
      "6\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 64s 166ms/step - loss: 0.0730 - accuracy: 0.9884 - val_loss: 0.7457 - val_accuracy: 0.8371\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 56s 146ms/step - loss: 0.0856 - accuracy: 0.9855 - val_loss: 0.8394 - val_accuracy: 0.8145\n",
      "Epoch 00002: early stopping\n",
      "7\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 66s 172ms/step - loss: 0.0840 - accuracy: 0.9848 - val_loss: 0.7708 - val_accuracy: 0.8415\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 58s 151ms/step - loss: 0.0669 - accuracy: 0.9891 - val_loss: 0.8236 - val_accuracy: 0.8524\n",
      "Epoch 00002: early stopping\n",
      "8\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 63s 164ms/step - loss: 0.0749 - accuracy: 0.9881 - val_loss: 0.9520 - val_accuracy: 0.8371\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 58s 150ms/step - loss: 0.0681 - accuracy: 0.9891 - val_loss: 0.8846 - val_accuracy: 0.8430\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 56s 146ms/step - loss: 0.0650 - accuracy: 0.9903 - val_loss: 0.9136 - val_accuracy: 0.8349\n",
      "Epoch 00003: early stopping\n",
      "9\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 66s 170ms/step - loss: 0.0699 - accuracy: 0.9881 - val_loss: 0.8624 - val_accuracy: 0.8459\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 56s 147ms/step - loss: 0.0632 - accuracy: 0.9909 - val_loss: 0.8622 - val_accuracy: 0.8451\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 57s 147ms/step - loss: 0.0641 - accuracy: 0.9914 - val_loss: 1.1228 - val_accuracy: 0.8115\n",
      "Epoch 00003: early stopping\n",
      "10\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 63s 164ms/step - loss: 0.0662 - accuracy: 0.9906 - val_loss: 1.0125 - val_accuracy: 0.8320\n",
      "Epoch 2/5\n",
      "385/385 [==============================] - 61s 159ms/step - loss: 0.0725 - accuracy: 0.9884 - val_loss: 0.9054 - val_accuracy: 0.8459\n",
      "Epoch 3/5\n",
      "385/385 [==============================] - 60s 157ms/step - loss: 0.0758 - accuracy: 0.9890 - val_loss: 1.0203 - val_accuracy: 0.7327\n",
      "Epoch 00003: early stopping\n",
      "Finished\n",
      "Model Accuracy = 85.01628664495115%\n",
      "Model Accuracy = 86.48208469055375%\n",
      "Model Accuracy = 87.45928338762215%\n",
      "Model Accuracy = 84.69055374592834%\n",
      "Model Accuracy = 86.97068403908796%\n",
      "Model Accuracy = 85.34201954397395%\n",
      "Model Accuracy = 82.89902280130293%\n",
      "Model Accuracy = 84.69055374592834%\n",
      "Model Accuracy = 75.8957654723127%\n",
      "Model Accuracy = 84.52768729641694%\n",
      "Model Accuracy = 86.15635179153095%\n",
      "The highest Accuracy: ['17-11-2020--12.54.00_92.83.h5'] with 92.83387622149837%\n",
      "------------------------------------------------------------------------\n",
      "12\n",
      "Neurons = 24 14 15\n",
      "training\n",
      "Fold Num = 1\n",
      "Epoch 1/5\n",
      "385/385 [==============================] - 63s 163ms/step - loss: 0.7182 - accuracy: 0.7335 - val_loss: 0.6323 - val_accuracy: 0.6311\n",
      "Epoch 2/5\n",
      "330/385 [========================>.....] - ETA: 8s - loss: 0.4154 - accuracy: 0.8284"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-eba3ced3fb46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtg_sendtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Started training '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' with neurons = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmessage_discord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Started training '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' with neurons = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrain_cross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmaxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxx_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxx_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_highest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_models/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxx_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxx_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-1df4d03decb4>\u001b[0m in \u001b[0;36mtrain_cross_val\u001b[0;34m(input_layer_neurons_val, first_layer_neurons_val, second_layer_neurons_val, mes)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint_best\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_layer_neurons = list(np.arange(18, 25))\n",
    "first_layer_neurons = list(np.arange(12, 17))\n",
    "second_layer_neurons = list(np.arange(12, 17))\n",
    "res = [[i, j, k]\n",
    "       for i in input_layer_neurons\n",
    "       for j in first_layer_neurons\n",
    "       for k in second_layer_neurons]\n",
    "res = res[::-1]\n",
    "res.remove([24, 16, 16])\n",
    "res.remove([24, 16, 15])\n",
    "\n",
    "maxx = 0\n",
    "count = 3\n",
    "maxx_acc = []\n",
    "maxx_i = []\n",
    "for i in res:\n",
    "    print(count)\n",
    "    neurons = [i[0], i[1], i[2]]\n",
    "    print('Neurons =', i[0], i[1], i[2])\n",
    "    message = 'model ' + str(count)\n",
    "    tg_sendtext('Started training ' + message + ' with neurons = ' + str(neurons))\n",
    "    message_discord('Started training ' + message + ' with neurons = ' + str(neurons))\n",
    "    train_cross_val(i[0], i[1], i[2], message)\n",
    "    time.sleep(5)\n",
    "    maxx, accuracy, maxx_acc, maxx_i = check_highest('saved_models/', maxx, maxx_acc, maxx_i)\n",
    "    message = message + ' ' + str([i[0], i[1], i[2]]) + ' with accuracy = ' + str(accuracy)\n",
    "    tg_sendtext('Finished training ' + message)\n",
    "    message_discord('Finished training ' + message)\n",
    "    count += 1\n",
    "    print('------------------------------------------------------------------------')\n",
    "    tg_sendtext('------------------------------------------------------------------------')\n",
    "    message_discord('------------------------------------------------------------------------')\n",
    "print('AHHHHHHH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "message = 'Model 1'\n",
    "train_cross_val(21, 14, 14, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideInput": false,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "Fold Num = 1 Epoch 1/10\n",
      "  4/153 [..............................] - ETA: 3:55:31 - loss: 990.3535 - accuracy: 0.5273 "
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "mes = 'Model 2'\n",
    "pat = 3\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n",
    "model_checkpoint_best = ModelCheckpoint('checkpoints/' + (datetime.datetime.utcnow()+datetime.timedelta(hours=5.5)).strftime(\"%d-%m-%Y--%H.%M.%S\") + '.h5', verbose=1, save_best_only=True)\n",
    "model_checkpoint = ModelCheckpoint('temp_checkpoint/' + \"model_{epoch:02d}\" + (datetime.datetime.utcnow()+datetime.timedelta(hours=5.5)).strftime(\"%d-%m-%Y--%H.%M.%S\") + '.h5', verbose=0, save_best_only=False, monitor='val_loss')\n",
    "model_history = []\n",
    "log_dir = \"logs/fit/\" + (datetime.datetime.utcnow()+datetime.timedelta(hours=5.5)).strftime(\"%d-%m-%Y--%H.%M.%S\")\n",
    "logs = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "### Model ###\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), kernel_initializer='random_normal', kernel_regularizer = l2(0.0009), activity_regularizer = l2(0.0005), activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, input_shape = X_train.shape[1:], kernel_initializer='random_normal', kernel_regularizer = l2(0.0009), activity_regularizer = None, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, input_shape = X_train.shape[1:], kernel_initializer='random_normal', kernel_regularizer = l2(0.0009), activity_regularizer = None, activation = 'relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(256, input_shape = X_train.shape[1:], kernel_initializer='random_normal', kernel_regularizer = l2(0.0009), activity_regularizer = None, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(128, input_shape = X_train.shape[1:], kernel_initializer='random_normal', kernel_regularizer = l2(0.0009), activity_regularizer = None, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(64, input_shape = X_train.shape[1:], kernel_initializer='random_normal', kernel_regularizer = l2(0.0009), activity_regularizer = None, activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(32, input_shape = X_train.shape[1:], kernel_initializer='random_normal', kernel_regularizer = l2(0.0009), activity_regularizer = None, activation = 'relu'))\n",
    "model.add(Dropout(0.08))\n",
    "\n",
    "model.add(Dense(16, input_shape = X_train.shape[1:], kernel_initializer='random_normal', kernel_regularizer = l2(0.0009), activity_regularizer = None, activation = 'relu'))\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print('training')\n",
    "print('Fold Num =', end=' ')\n",
    "for i in range(n_folds):\n",
    "    print(i+1, end=' ')\n",
    "    t_x, val_x, t_y, val_y = train_test_split(inputs, targets, test_size=0.2,\n",
    "                                               random_state = np.random.randint(1,1000, 1)[0])\n",
    "\n",
    "    model.fit(t_x, t_y, epochs=10, batch_size=64, callbacks=[early_stopping, model_checkpoint, model_checkpoint_best, logs], verbose=1, validation_split=0.2)\n",
    "\n",
    "    scores = model.evaluate(val_x, val_y, verbose=0)\n",
    "\n",
    "    tg_sendtext(f'Finished fold number {i+1} of {mes} with accuracy = {scores[1]*100}%')\n",
    "    message_discord(f'Finished fold number {i+1} of {mes} with accuracy = {scores[1]*100}%')\n",
    "    model.save('saved_models/' + (datetime.datetime.utcnow()+datetime.timedelta(hours=5.5)).strftime(\"%d-%m-%Y--%H.%M.%S\") + '.h5')\n",
    "    check_highest_custom('temp_checkpoint/')\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideOutput": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pothole_detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
